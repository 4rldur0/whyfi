{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iJIaFzs3_5JI",
        "W2Emyy8JEfYC",
        "uLdnuNJR8QAm"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM1fdND6DyEHPI+xds74Ayc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4rldur0/whyfi/blob/xeoyeon/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 초기 설정"
      ],
      "metadata": {
        "id": "cC9rzq7eai-h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMfHySIj6nnG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/RAG"
      ],
      "metadata": {
        "id": "UnRtUY0U61M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers chromadb langchain langchain_community langchain-chroma"
      ],
      "metadata": {
        "id": "uRlMWYW28arl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. data 불러오기"
      ],
      "metadata": {
        "id": "iJIaFzs3_5JI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/RAG/dataset/cleaned_word_dict.csv'\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "iPg9guWzFg2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pdf 가져와서 chunk하기"
      ],
      "metadata": {
        "id": "W2Emyy8JEfYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "file_name = # 읽어오려는 파일 경로\n",
        "\n",
        "loader = PyPDFLoader(file_name)\n",
        "pages = loader.load()\n",
        "text = \"\"\n",
        "for page in pages:\n",
        "    sub = page.page_content\n",
        "    text += sub"
      ],
      "metadata": {
        "id": "Ww-X-VFtEim9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# token size 기준으로 contents split\n",
        "tokenizer = AutoTokenizer.from_pretrained(ENCODER)\n",
        "text_splitter = CharacterTextSplitter.from_huggingface_tokenizer(\n",
        "            tokenizer,\n",
        "            chunk_size=CHUNK_SIZE,\n",
        "            chunk_overlap=CHUNK_OVERLAP,\n",
        "            separator=\"\\n\" # default: \"\\n\\n\"\n",
        "        )\n",
        "\n",
        "\n",
        "documents=[] # split 한 문서들을 담기 위한 array\n",
        "\n",
        "split_conts = text_splitter.split_text(text)\n",
        "for chunk_idx, split_cont in enumerate(split_conts):\n",
        "    documents.append(Document(\n",
        "        page_content=split_cont,\n",
        "        metadata={\n",
        "            \"file_name\": file_name,\n",
        "        },\n",
        "        id=chunk_idx,\n",
        "    ))\n",
        "    idx+=1\n",
        "\n",
        "vectorstore.add_documents(documents)"
      ],
      "metadata": {
        "id": "jcKE3UxdEk0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## website 문서 로딩하기"
      ],
      "metadata": {
        "id": "uLdnuNJR8QAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load documents from web\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "web_loader = WebBaseLoader([\n",
        "    \"링크 삽입\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "data = web_loader.load()"
      ],
      "metadata": {
        "id": "eRgMGULC_8nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Split documents into chunks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap = 0\n",
        ")\n",
        "\n",
        "all_splits = text_splitter.split_documents(data)\n",
        "\n",
        "all_splits[0]\n",
        "출처: https://rfriend.tistory.com/832 [R, Python 분석과 프로그래밍의 친구 (by R Friend):티스토리]"
      ],
      "metadata": {
        "id": "WXP97Wk7AOnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. chromaDB에 데이터 저장하기"
      ],
      "metadata": {
        "id": "EJllvlFiAUVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-huggingface"
      ],
      "metadata": {
        "id": "7ZFBiU88C91n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#기존 임베딩 결과만 가져오기\n",
        "import os\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embedding =\"dragonkue/BGE-m3-ko\"\n",
        "collection_name = \"Chroma_Collection\"\n",
        "chroma_path = \"/content/drive/MyDrive/Colab Notebooks/RAG\" #데이터 저장 경로\n",
        "\n",
        "# Init chromadb\n",
        "embedding_func = HuggingFaceEmbeddings(model_name=embedding, encode_kwargs={'normalize_embeddings':True},)\n",
        "vectorstore = Chroma(\n",
        "    collection_name,\n",
        "    embedding_function=embedding_func,\n",
        "    persist_directory=chroma_path,\n",
        "    collection_metadata={\"max_size\": 1000}  # 용량 설정 (1000개로 확장)\n",
        ")\n"
      ],
      "metadata": {
        "id": "8q3EifDs_3Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 컬렉션 삭제\n",
        "vectorstore._client.delete_collection(\"Chroma_Collection\")\n",
        "\n",
        "# 새로운 컬렉션 생성\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"Chroma_Collection\",\n",
        "    embedding_function=embedding_func,\n",
        "    persist_directory=\"/content/drive/MyDrive/Colab Notebooks/RAG\",\n",
        "    collection_metadata={\"max_size\": 1000}\n",
        ")\n"
      ],
      "metadata": {
        "id": "Dmi5KRbtLUrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document # 데이터의 각 row를 document 객체로 변환하여 저장하기 위함\n",
        "\n",
        "# vectorDB에 data 추가하는 함수\n",
        "def add_data_to_vectorstore(data, vectorstore):\n",
        "  for index, row in data.iterrows(): # row라는 변수에 각 행을 반복적으로 가져옴.\n",
        "    text = row.get(\"Content\",\"\")\n",
        "    metadata = row.to_dict() #행 전체를 딕셔너리 형태로 변환\n",
        "    metadata[\"source\"] = metadata.get(\"source\", f\"row_{index}\")   # source 필드 추가 (기본값으로 행 번호를 사용하거나 특정 열에서 가져오기)\n",
        "    document = Document(page_content=text, metadata=metadata) #cocument 객체를 생성\n",
        "    vectorstore.add_texts([document.page_content],[document.metadata]) # db에 데이터 추가\n",
        "\n",
        "add_data_to_vectorstore(data, vectorstore)"
      ],
      "metadata": {
        "id": "6MjvPo_OG4j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Retriever 및 프롬프트 설정"
      ],
      "metadata": {
        "id": "pydocZFnbP4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a retriever to search in the vectorstore\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3}) #검색 시 가장 관련성 높은 3개의 문서를 반환하라는 뜻"
      ],
      "metadata": {
        "id": "z0WAxsuOIonS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "# system_template=\"\"\"\n",
        "# You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
        "\n",
        "# You MUST answer in Korean.\n",
        "\n",
        "# Question: {question}\n",
        "# Context: {context}\n",
        "# Answer:\n",
        "# \"\"\"\n",
        "system_template = \"\"\"당신은 금융 전문가로, 복잡한 금융 용어를 쉽게 설명하는 데 능숙합니다. 사용자가 금융과 관련된 용어에 대해 질문하면, 다음을 수행하세요:\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "용어 설명: 질문에 포함된 금융 용어를 간단하고 명확한 언어로 설명하세요.\n",
        "추가 정보: 사용자가 해당 개념을 더 잘 이해할 수 있도록, 실제 사례나 비유를 포함하여 설명을 보완하세요.\n",
        "관련 용어: 해당 용어와 연관된 다른 금융 용어나 개념을 최대 3개까지 추천하세요.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    SystemMessagePromptTemplate.from_template(system_template),\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(messages)"
      ],
      "metadata": {
        "id": "Ry-kcYg3M7ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. gemini api 설정 및 chain 구현하기"
      ],
      "metadata": {
        "id": "Y29G7jl4F1Tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-vertexai"
      ],
      "metadata": {
        "id": "VfkpxLXDTZQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"your_project_id\"\n",
        "REGION = \"your_region\"\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "rmnNDrjsUCXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain_google_vertexai import VertexAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "vertexai.init(project = PROJECT_ID , location = REGION)\n",
        "\n",
        "chain_type_kwargs = {\n",
        "    \"prompt\": prompt,\n",
        "    \"document_variable_name\": \"context\",  # 'context'가 documents를 받을 변수임을 명시\n",
        "}\n",
        "llm = VertexAI(\n",
        "    temperature=0,\n",
        "    model_name=\"gemini-pro\",\n",
        "    max_output_tokens=1024\n",
        ")\n",
        "\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever = retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs=chain_type_kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "UshxPJxgNiU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain 사용 예시\n",
        "question = \"가동률이란?\"\n",
        "result = chain({\"question\": question})\n",
        "\n",
        "print(\"Answer:\", result[\"answer\"])\n",
        "print(\"Sources:\", result[\"source_documents\"])"
      ],
      "metadata": {
        "id": "GGimgZgpYGpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. streamlit 으로 간단하게 웹 ui 구현하기\n",
        "1. [ngrok](https://dashboard.ngrok.com/) 에 접속 후 회원가입\n",
        "2. 로그인 후 뜨는 authtoken 번호를 아래의 코드에 붙여넣기\n"
      ],
      "metadata": {
        "id": "h_plpPTTGzhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "w43K67gkG6QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import vertexai\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain_google_vertexai import VertexAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "import re\n",
        "\n",
        "embedding =\"dragonkue/BGE-m3-ko\"\n",
        "collection_name = \"Chroma_Collection\"\n",
        "chroma_path = \"/content/drive/MyDrive/Colab Notebooks/RAG\" #데이터 저장 경로\n",
        "\n",
        "# Init chromadb\n",
        "embedding_func = HuggingFaceEmbeddings(model_name=embedding, encode_kwargs={'normalize_embeddings':True},)\n",
        "vectorstore = Chroma(\n",
        "    collection_name,\n",
        "    embedding_function=embedding_func,\n",
        "    persist_directory=chroma_path,\n",
        "    collection_metadata={\"max_size\": 1000}  # 용량 설정 (1000개로 확장)\n",
        ")\n",
        "\n",
        "#retriever\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "#초기화\n",
        "system_template = \"\"\"당신은 금융 전문가로, 복잡한 금융 용어를 쉽게 설명하는 데 능숙합니다. 사용자가 금융과 관련된 용어에 대해 질문하면, 다음을 수행하세요:\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "용어 설명: 질문에 포함된 금융 용어를 간단하고 명확한 언어로 설명하세요.\n",
        "추가 정보: 사용자가 해당 개념을 더 잘 이해할 수 있도록, 실제 사례나 비유를 포함하여 설명을 보완하세요.\n",
        "관련 용어: 해당 용어와 연관된 다른 금융 용어를 추천하세요.\n",
        "\n",
        "단, 반드시 한국어로 답변해야 하며, 전체 Answer의 길이가 8줄을 넘어가지 않도록 하세요.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    SystemMessagePromptTemplate.from_template(system_template),\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "#gemini\n",
        "PROJECT_ID = \"your_project_id\"\n",
        "REGION = \"your_region\"\n",
        "\n",
        "vertexai.init(project = PROJECT_ID , location = REGION)\n",
        "\n",
        "chain_type_kwargs = {\n",
        "    \"prompt\": prompt,\n",
        "    \"document_variable_name\": \"context\",  # 'context'가 documents를 받을 변수임을 명시\n",
        "}\n",
        "llm = VertexAI(\n",
        "    temperature=0,\n",
        "    model_name=\"gemini-pro\",\n",
        "    max_output_tokens=1024\n",
        ")\n",
        "\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever = retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs=chain_type_kwargs\n",
        ")\n",
        "\n",
        "#streamlit 설계\n",
        "st.set_page_config(page_title=\"금융용어알리미 : WhyFi\")\n",
        "\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <h1 style='color: white; text-align: center;'>금융용어알리미 : WhyFi</h1>\n",
        "    <h2 style='color: gray; text-align: center; font-size: 20px;'>모르는 금융 용어? 이제 쉽게 찾아보세요!</h2>\n",
        "    <br>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True,\n",
        ")\n",
        "\n",
        "\n",
        "user_question = st.text_input(\"금융 용어를 검색해보세요.\", value=\"\", placeholder=\"예: 가동률이란?\")\n",
        "if user_question:\n",
        "    with st.spinner(\"답변을 생성 중입니다...\"):\n",
        "        result = chain({\"question\": user_question})\n",
        "\n",
        "    # 결과 출력\n",
        "    st.markdown(\"### 📖 답변 📖\")\n",
        "\n",
        "    # 텍스트에서 헤더(##)를 분리하고 스타일 적용\n",
        "    answer_text = result[\"answer\"]\n",
        "\n",
        "    # 헤더와 본문 분리\n",
        "    header_match = re.match(r\"^##\\s*(.*)\", answer_text)\n",
        "    if header_match:\n",
        "        header = header_match.group(1)  # 헤더 부분\n",
        "        body = re.sub(r\"^##\\s*.*\\n*\", \"\", answer_text, flags=re.MULTILINE)  # 나머지 텍스트\n",
        "    else:\n",
        "        header = \"\"\n",
        "        body = answer_text\n",
        "\n",
        "    # 헤더와 본문 각각 스타일링\n",
        "    st.markdown(\n",
        "        f\"<div style='font-size:20px; font-weight:bold; line-height:1.8;'>{header}</div>\",\n",
        "        unsafe_allow_html=True,\n",
        "    )\n",
        "    st.markdown(\n",
        "        f\"<div style='font-size:16px; line-height:1.6;'>{body}</div>\",\n",
        "        unsafe_allow_html=True,\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### 📚 참고 출처 📚\")\n",
        "    for doc in result[\"source_documents\"]:\n",
        "        st.markdown(\n",
        "            f\"<div style='font-size:14px; line-height:1.4;'>- {doc.metadata['source']}</div>\",\n",
        "            unsafe_allow_html=True,\n",
        "        )\n",
        "\n",
        "#         # 결과 출력\n",
        "# st.markdown(\"#### 📖 답변:\")\n",
        "# st.markdown(f\"<div style='font-size:16px; line-height:1.6;'>{result['answer']}</div>\", unsafe_allow_html=True)\n",
        "\n",
        "# st.markdown(\"#### 📚 참고 출처:\")\n",
        "# for doc in result[\"source_documents\"]:\n",
        "#     st.markdown(f\"<div style='font-size:14px; line-height:1.4;'>- {doc.metadata['source']}</div>\", unsafe_allow_html=True)\n"
      ],
      "metadata": {
        "id": "e7UsYrFsHywm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "pl-xgaD2KBrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#개인 토큰 번호 입력\n",
        "!ngrok authtoken [개인 토큰 번호]"
      ],
      "metadata": {
        "id": "bifsVLSMKsFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "!streamlit run app.py&>/dev/null&"
      ],
      "metadata": {
        "id": "CBFpB947KO7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "publ_url = ngrok.connect(addr=\"8501\")"
      ],
      "metadata": {
        "id": "xwHClxWMKX7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "publ_url"
      ],
      "metadata": {
        "id": "pE4A6SZdKcmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps"
      ],
      "metadata": {
        "id": "A9KYjg9iKmLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill 13177 17180 12664"
      ],
      "metadata": {
        "id": "ss7eHUUKKkFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "NQPKytE6KnIk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}